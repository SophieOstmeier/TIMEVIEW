{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a demo experiment for **training**, when running an experiment, load model configuration and dataset first.\n",
    "\n",
    "Then pass it into the train_eval() function to get the best model, which you can subsequently use to perform inferencing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from tts.data import synthetic_tumor_data, TTSDataset\n",
    "from tts.config import Config\n",
    "from train_eval.training import training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tl522/miniconda/envs/tabular-dl/lib/python3.8/site-packages/pytorch_lightning/utilities/seed.py:47: LightningDeprecationWarning: `pytorch_lightning.utilities.seed.seed_everything` has been deprecated in v1.8.0 and will be removed in v2.0.0. Please use `lightning_fabric.utilities.seed.seed_everything` instead.\n",
      "  rank_zero_deprecation(\n",
      "Global seed set to 0\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/tl522/miniconda/envs/tabular-dl/lib/python3.8/site-packages/pytorch_lightning/trainer/setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "Missing logger folder: logs/run_0/tts\n",
      "/home/tl522/miniconda/envs/tabular-dl/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 36 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/tl522/miniconda/envs/tabular-dl/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:84: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 200. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/home/tl522/miniconda/envs/tabular-dl/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 36 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    }
   ],
   "source": [
    "# run_seed = np.arange(10) for multiple runs\n",
    "run_seeds = [0]\n",
    "\n",
    "for seed in run_seeds:\n",
    "    # load config\n",
    "    # NOTE: remember to load best hyperparams found after search!!\n",
    "    config = Config(n_features=4, n_basis=5, T=1, seed=seed)\n",
    "    # side note: batch_size seems slightly large here?\n",
    "    # I would recommend much smaller e.g. 128 or make it a tuneable hyperparameter \n",
    "    # (which I did in demo_tuning_experiment.ipynb)\n",
    "    config.training.batch_size = 3000\n",
    "    \n",
    "    # load dataset\n",
    "    X, ts, ys = synthetic_tumor_data(2000,20,1.0,0.0,seed=seed,equation='wilkerson')\n",
    "    dataset = TTSDataset(config, (X, ts, ys))\n",
    "\n",
    "    litmodel = training(seed, config, dataset)\n",
    "    \n",
    "    # add inferencing/evaluation code... whatever you may wish to do with a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tts.visualize import simple_interactive_plot\n",
    "from tts.data import  _get_tumor_feature_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f8136cee76496899a4c1aa23720c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=20.0, description='age', max=80.0, min=20.0, step=0.01), FloatSlider(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def trajectory(t, **x):\n",
    "    feature_names = [\"age\",\"weight\",\"initial_tumor_volume\",\"dosage\"]\n",
    "    features = np.array([x[feature_name] for feature_name in feature_names])\n",
    "    return litmodel.model.forecast_trajectory(features,t)\n",
    "\n",
    "\n",
    "simple_interactive_plot(trajectory, 1, (0,2), _get_tumor_feature_ranges(\"age\",\"weight\",\"initial_tumor_volume\",\"dosage\"), n_points=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a0bd1a01bc4a638f6e66af091849bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=20.0, description='age', max=80.0, min=20.0, step=0.01), FloatSlider(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ground truth\n",
    "from tts.visualize import simple_interactive_plot\n",
    "from tts.data import _tumor_volume_2,  _get_tumor_feature_ranges\n",
    "simple_interactive_plot(_tumor_volume_2, 1, (0,2), _get_tumor_feature_ranges(\"age\",\"weight\",\"initial_tumor_volume\",\"dosage\"), n_points=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
