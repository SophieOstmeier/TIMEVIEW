{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple results found for the given dataset and model\n",
      "We take the last one but it may produce unexpected results\n",
      "Overriding data folder with /dataNAS/people/sostm/TIMEVIEW/experiments/data\n"
     ]
    }
   ],
   "source": [
    "# This script is used to create Figure 1 in the paper\n",
    "# It requires running TIMEVIEW_interface_only.sh or Table_3.sh first to generate the results\n",
    "\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from timeview.visualize import expert_tts_plot, grid_tts_plot\n",
    "from experiments.datasets import load_dataset\n",
    "from experiments.benchmark import load_column_transformer, create_benchmark_datasets_if_not_exist\n",
    "from timeview.lit_module import load_model\n",
    "from experiments.baselines import YNormalizer\n",
    "from experiments.analysis.analysis_utils import find_results\n",
    "\n",
    "# dataset_name = \"synthetic_tumor_wilkerson_1\"\n",
    "# dataset_name = \"airfoil_log\"\n",
    "# dataset_name = \"stress-strain-curves\"\n",
    "dataset_name = \"flchain_1000\"\n",
    "model_name = \"TTS\"\n",
    "root = \"/dataNAS/people/sostm/TIMEVIEW/experiments\"\n",
    "\n",
    "create_benchmark_datasets_if_not_exist(dataset_description_path=f\"{root}/dataset_descriptions\")\n",
    "\n",
    "results = find_results(dataset_name, model_name, results_dir=f'{root}/benchmarks', summary_filename=f'{root}/benchmarks/summary.json',)\n",
    "\n",
    "if len(results) == 0:\n",
    "    print(f\"No results found for {dataset_name} and {model_name}\")\n",
    "    print(\"Make sure you run your experiments from ../run_scripts\")\n",
    "elif len(results) > 1:\n",
    "    print(\"Multiple results found for the given dataset and model\")\n",
    "    print(\"We take the last one but it may produce unexpected results\")\n",
    "\n",
    "timestamp = results[-1]\n",
    "\n",
    "litmodel = load_model(timestamp, seed=661058651, benchmarks_folder=f\"{root}/benchmarks\")\n",
    "dataset = load_dataset(dataset_name, dataset_description_path=f\"{root}/dataset_descriptions\", data_folder=f\"{root}/data\")\n",
    "column_transformer = load_column_transformer(timestamp, benchmarks_dir=f\"{root}/benchmarks\")\n",
    "y_normalizer = YNormalizer.load_from_benchmark(timestamp, model_name, benchmark_dir=f\"{root}/benchmarks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# expert_tts_plot(litmodel, dataset, (0.2,0.5), n_points=100, figsize=(3.5,3.5), column_transformer=column_transformer, y_normalizer=y_normalizer, display_feature_names=None,default_values=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from timeview.basis import BSplineBasis\n",
    "\n",
    "def tts_inference(litmodel, dataset, feature_combinations, n_points=100, y_normalizer=None, column_transformer=None, return_transition_points=False):\n",
    "    \"\"\"\n",
    "    Perform inference on trajectory time series model for multiple feature combinations.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    litmodel : TTSModel\n",
    "        The trained trajectory time series model\n",
    "    dataset : Dataset\n",
    "        The dataset object containing feature information\n",
    "    feature_combinations : list[dict] or pd.DataFrame\n",
    "        List of dictionaries or DataFrame containing feature combinations to evaluate\n",
    "        Each dictionary/row should contain feature names as keys/columns\n",
    "    n_points : int, optional (default=100)\n",
    "        Number of points to evaluate the trajectory\n",
    "    y_normalizer : sklearn transformer, optional\n",
    "        Transformer to inverse transform the predictions if used during training\n",
    "    column_transformer : sklearn ColumnTransformer, optional\n",
    "        Transformer used to preprocess features during training\n",
    "    return_transition_points : bool, optional (default=False)\n",
    "        Whether to return transition points in addition to trajectories\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict with keys:\n",
    "        't' : ndarray \n",
    "            Time points for the trajectories\n",
    "        'trajectories' : ndarray\n",
    "            Predicted trajectories for each feature combination\n",
    "        'transition_points' : list[tuple], optional\n",
    "            List of (time_points, values) tuples for transition points if return_transition_points=True\n",
    "    \"\"\"\n",
    "    # Convert input to DataFrame if it's a list of dictionaries\n",
    "    if isinstance(feature_combinations, list):\n",
    "        feature_combinations = pd.DataFrame(feature_combinations)\n",
    "    \n",
    "    # Verify features\n",
    "    feature_names = dataset.get_feature_names()\n",
    "    for feature in feature_names:\n",
    "        if feature not in feature_combinations.columns:\n",
    "            raise ValueError(f\"Missing feature: {feature}\")\n",
    "    \n",
    "    # Get time points\n",
    "    time_horizon = litmodel.config.T\n",
    "    t = np.linspace(0, time_horizon, n_points)\n",
    "    \n",
    "    # Initialize BSpline basis\n",
    "    config = litmodel.config\n",
    "    bspline = BSplineBasis(\n",
    "        config.n_basis,\n",
    "        (0, config.T),\n",
    "        internal_knots=config.internal_knots\n",
    "    )\n",
    "    \n",
    "    # Transform features if needed\n",
    "    if column_transformer is not None:\n",
    "        transformed_features = column_transformer.transform(feature_combinations[feature_names])\n",
    "    else:\n",
    "        transformed_features = feature_combinations[feature_names].values\n",
    "        \n",
    "    # Get trajectories\n",
    "    trajectories = []\n",
    "    transition_points_list = []\n",
    "    \n",
    "    for i in range(len(transformed_features)):\n",
    "        # Get trajectory\n",
    "        trajectory = litmodel.model.forecast_trajectory(transformed_features[i], t)\n",
    "        \n",
    "        # Apply inverse transform if needed\n",
    "        if y_normalizer is not None:\n",
    "            trajectory = y_normalizer.inverse_transform(trajectory.reshape(-1, 1)).flatten()\n",
    "            \n",
    "        trajectories.append(trajectory)\n",
    "        \n",
    "        # Get transition points if requested\n",
    "        if return_transition_points:\n",
    "            coeffs = litmodel.model.predict_latent_variables(\n",
    "                transformed_features[i].reshape(1, -1)\n",
    "            )\n",
    "            _, transition_points = bspline.get_template_from_coeffs(coeffs[0, :])\n",
    "            \n",
    "            # Get values at transition points\n",
    "            transition_values = litmodel.model.forecast_trajectory(\n",
    "                transformed_features[i], \n",
    "                np.array(transition_points)\n",
    "            )\n",
    "            \n",
    "            # Apply inverse transform if needed\n",
    "            if y_normalizer is not None:\n",
    "                transition_values = y_normalizer.inverse_transform(\n",
    "                    transition_values.reshape(-1, 1)\n",
    "                ).flatten()\n",
    "                \n",
    "            transition_points_list.append((transition_points, transition_values))\n",
    "    \n",
    "    result = {\n",
    "        't': t,\n",
    "        'trajectories': np.array(trajectories)\n",
    "    }\n",
    "    \n",
    "    if return_transition_points:\n",
    "        result['transition_points'] = transition_points_list\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'your_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 24\u001b[0m\n\u001b[1;32m      1\u001b[0m settings \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     {\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m65\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     }\n\u001b[1;32m     20\u001b[0m ]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Get trajectories\u001b[39;00m\n\u001b[1;32m     23\u001b[0m results \u001b[38;5;241m=\u001b[39m tts_inference(\n\u001b[0;32m---> 24\u001b[0m     litmodel\u001b[38;5;241m=\u001b[39m\u001b[43myour_model\u001b[49m,\n\u001b[1;32m     25\u001b[0m     dataset\u001b[38;5;241m=\u001b[39myour_dataset,\n\u001b[1;32m     26\u001b[0m     feature_combinations\u001b[38;5;241m=\u001b[39msettings\n\u001b[1;32m     27\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'your_model' is not defined"
     ]
    }
   ],
   "source": [
    "settings = [\n",
    "    {\n",
    "        \"age\": 65,\n",
    "        \"creatinine\": 1.2,\n",
    "        \"flc.grp\": \"normal\",\n",
    "        \"kappa\": 1.5,\n",
    "        \"lambda\": 1.0,\n",
    "        \"mgus\": 0,\n",
    "        \"sex\": \"M\"\n",
    "    },\n",
    "    {\n",
    "        \"age\": 75,\n",
    "        \"creatinine\": 1.5,\n",
    "        \"flc.grp\": \"high\",\n",
    "        \"kappa\": 2.0,\n",
    "        \"lambda\": 1.3,\n",
    "        \"mgus\": 1,\n",
    "        \"sex\": \"F\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Get trajectories\n",
    "results = tts_inference(\n",
    "    litmodel=litmodel,\n",
    "    dataset=dataset,\n",
    "    feature_combinations=settings\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
